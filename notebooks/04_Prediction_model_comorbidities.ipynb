{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Creating a prediction model using Poisson Regression Model](#toc1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Creating a prediction model using Poisson Regression Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_comp_df = pd.read_parquet('..\\\\data\\\\feature_store\\\\city_comp_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ensure that categorical variables are properly specified\n",
    "categorical_vars = [ 'age_cat', 'gender', 'max_bmi_cat', 'max_major_city']\n",
    "for var in categorical_vars:\n",
    "    city_comp_df[var] = city_comp_df[var].astype('category')\n",
    "\n",
    "reference_city = 'Riyadh'  # e.g., 'New York' or whichever city you prefer\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Split the data into training and testing sets.\n",
    "# ----------------------------------------------------------\n",
    "# For reproducibility, set a random_state (e.g., 42)\n",
    "\n",
    "train_data, test_data = train_test_split(city_comp_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Fit a Poisson regression model on the training data.\n",
    "# ----------------------------------------------------------\n",
    "# Use the same formula as in your robust model (without the clustering for prediction purposes).\n",
    "formula_full_with_policy = (\n",
    "    'total_complications ~ C(max_major_city, Treatment(reference=\"%s\"))  + age + C(gender) + max_bmi + total_comorbidities + total_dm_icd'\n",
    "    % reference_city\n",
    ")\n",
    "\n",
    "# Fit the model on the training data.\n",
    "poisson_cluster_model = smf.glm(\n",
    "    formula=formula_full_with_policy,\n",
    "    data=city_comp_df,\n",
    "    family=smf.families.Poisson()\n",
    ").fit(cov_type='cluster', cov_kwds={'groups': city_comp_df['policy_number']})\n",
    "\n",
    "# Optionally, view the training model's summary:\n",
    "print(poisson_cluster_model.summary())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Use the fitted model to predict complication counts on the test data.\n",
    "# ----------------------------------------------------------\n",
    "test_data = test_data.copy()  # To avoid SettingWithCopyWarning\n",
    "test_data['predicted_complications'] = poisson_cluster_model.predict(test_data)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. Evaluate the prediction accuracy.\n",
    "# ----------------------------------------------------------\n",
    "# Calculate common metrics: Mean Squared Error (MSE) and Mean Absolute Error (MAE)\n",
    "mse = mean_squared_error(test_data['total_complications'], test_data['predicted_complications'])\n",
    "mae = mean_absolute_error(test_data['total_complications'], test_data['predicted_complications'])\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5. Visualize Actual vs. Predicted complication counts.\n",
    "# ----------------------------------------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(test_data['total_complications'], test_data['predicted_complications'], alpha=0.6)\n",
    "plt.plot([test_data['total_complications'].min(), test_data['total_complications'].max()],\n",
    "         [test_data['total_complications'].min(), test_data['total_complications'].max()],\n",
    "         color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.xlabel(\"Actual Number of Complications\")\n",
    "plt.ylabel(\"Predicted Number of Complications\")\n",
    "plt.title(\"Actual vs. Predicted Complication Counts\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Prepare the data for prediction modeling using scikit-learn.\n",
    "# -------------------------------------------------------------------\n",
    "# Select predictors and the outcome.\n",
    "predictors = ['max_major_city', 'age', 'gender', 'max_bmi', 'total_comorbidities']\n",
    "y = city_comp_df['total_complications']\n",
    "X = city_comp_df[predictors]\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables.\n",
    "# For max_major_city, set \"Riyadh\" as the baseline by dropping the first dummy.\n",
    "X_encoded = pd.get_dummies(X, columns=['max_major_city', 'gender'], drop_first=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Split the data into training and testing sets.\n",
    "# -------------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Create and train the Poisson regression prediction model.\n",
    "# -------------------------------------------------------------------\n",
    "# Note: PoissonRegressor is available in scikit-learn (v0.23+).\n",
    "# alpha=0.0 disables regularization, and max_iter ensures convergence.\n",
    "poisson_reg = PoissonRegressor(alpha=0.0, max_iter=1000)\n",
    "poisson_reg.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Predict the number of complications on the test set.\n",
    "# -------------------------------------------------------------------\n",
    "y_pred = poisson_reg.predict(X_test)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Evaluate the prediction accuracy.\n",
    "# -------------------------------------------------------------------\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Random Forest Regressor\n",
    "# -------------------------------------------------------------\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest predictions.\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. XGBoost Regressor\n",
    "# -------------------------------------------------------------\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost predictions.\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Print the prediction results.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Create a dictionary mapping each model's name to its corresponding MSE and MAE.\n",
    "results = {\n",
    "    \"PoissonRegressor\": {\"MSE\": mse, \"MAE\": mae},\n",
    "    \"Random Forest Regressor\": {\"MSE\": mse_rf, \"MAE\": mae_rf},\n",
    "    \"XGBoost Regressor\": {\"MSE\": mse_xgb, \"MAE\": mae_xgb},\n",
    "}\n",
    "\n",
    "# Loop through the dictionary and print the results in an efficient manner.\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name} Prediction Results:\")\n",
    "    print(f\"Mean Squared Error (MSE): {metrics['MSE']:.3f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {metrics['MAE']:.3f}\\n\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Plot the prediction vs actual results.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Define the predictions and titles in a list for efficient plotting.\n",
    "predictions = [\n",
    "    (y_pred, \"Poisson: Actual vs. Predicted\"),\n",
    "    (y_pred_rf, \"Random Forest: Actual vs. Predicted\"),\n",
    "    (y_pred_xgb, \"XGBoost: Actual vs. Predicted\")\n",
    "]\n",
    "\n",
    "# Determine the range for the ideal fit line.\n",
    "x_min, x_max = y_test.min(), y_test.max()\n",
    "\n",
    "# Create a figure with 1 row and 3 columns.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loop over the axes and corresponding prediction data.\n",
    "for ax, (y_pred_current, title) in zip(axes, predictions):\n",
    "    ax.scatter(y_test, y_pred_current, alpha=0.6)\n",
    "    ax.plot([x_min, x_max], [x_min, x_max], 'r--', label=\"Ideal Fit\")\n",
    "    ax.set_xlabel(\"Actual Complication Count\")\n",
    "    ax.set_ylabel(\"Predicted Complication Count\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model for deployment\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "with open(\"..\\\\models\\\\poisson_reg_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
