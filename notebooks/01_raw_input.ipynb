{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import janitor\n",
    "\n",
    "from utils import data_path, list_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Stage Documentation\n",
    "\n",
    "### The loading stage focuses on ensuring data is correctly ingested with proper data types and meaningful column names.\n",
    "\n",
    "**Best Practices Followed:**\n",
    "1. **Defining Data Types:**\n",
    "   - A `dtype_dict` is created to explicitly specify data types for each column in the dataset. This improves memory efficiency and ensures correct data interpretation.\n",
    "   - Examples include treating `gender` as a categorical variable and `bmi` as a float for precise numerical analysis.\n",
    "\n",
    "2. **Using a Column Lookup Table:**\n",
    "   - A dictionary (`column_lookup`) is used to rename columns to more descriptive and meaningful names. This makes the dataset easier to understand and work with.\n",
    "\n",
    "3. **Efficient Loading:**\n",
    "   - The dataset is loaded using `pd.read_csv` with the `dtype_dict`, minimizing post-load type conversions and errors.\n",
    "\n",
    "4. **Validation:**\n",
    "   - The data types and the first few rows are printed to verify successful loading and renaming.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prin the list of data files\n",
    "print(list_data_files())\n",
    "\n",
    "# Define the path to the raw data file\n",
    "raw_data_path =  data_path()+ \"\\\\\" + list_data_files()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data types for each column in the dataset\n",
    "dtype_dict = {\n",
    "    \"MEMBER_CODE\": \"int64\",    # De-identified member ID, stored as float to match dataset format\n",
    "    \"Age\": \"int64\",             # Age of the member\n",
    "    \"GENDER\": \"category\",       # Gender is a categorical variable\n",
    "    \"POLICY_NO\": \"int64\",       # Policy number, stored as integer\n",
    "    \"CMS_Score\": \"int64\",       # Charlson comorbidity index score, stored as integer\n",
    "    \"ICD_CODE\": \"category\",     # ICD-10 codes are categorical\n",
    "    \"ICD_desc\": \"string\",       # ICD-10 description as a string\n",
    "    \"City\": \"string\",           # City as a string, handling missing values separately\n",
    "    \"CLAIM_TYPE\": \"category\",   # Claim type is categorical\n",
    "    \"BMI\": \"float64\"            # BMI as a float\n",
    "}\n",
    "\n",
    "# Column renaming lookup table\n",
    "column_lookup = {\n",
    "    \"MEMBER_CODE\": \"member_code\",\n",
    "    \"Age\": \"age\",\n",
    "    \"GENDER\": \"gender\",\n",
    "    \"POLICY_NO\": \"policy_number\",\n",
    "    \"CMS_Score\": \"cms_score\",\n",
    "    \"ICD_CODE\": \"icd_code\",\n",
    "    \"ICD_desc\": \"icd_description\",\n",
    "    \"City\": \"city\",\n",
    "    \"CLAIM_TYPE\": \"claim_type\",\n",
    "    \"BMI\": \"bmi\"\n",
    "}\n",
    "\n",
    "\n",
    "# Load the dataset with specified data types\n",
    "raw_data = pd.read_csv(raw_data_path, dtype=dtype_dict)\n",
    "\n",
    "# Rename columns using the lookup table\n",
    "raw_data.rename(columns=column_lookup, inplace=True)\n",
    "\n",
    "# Verify the data types after loading\n",
    "print(raw_data.dtypes)\n",
    "\n",
    "# Display the first few rows to confirm successful loading\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data and Duplicates Documentation\n",
    "\n",
    "### The second stage focuses on ensuring data integrity by handling missing values and duplicates.\n",
    "\n",
    "**Best Practices Followed:**\n",
    "1. **Identifying Missing Data:**\n",
    "   - A summary of missing values is generated to identify columns with missing entries.\n",
    "\n",
    "2. **Handling Missing Data:**\n",
    "   - Missing values in the `city` column are replaced with \"Unknown\" as an example strategy.\n",
    "   - Other strategies can include imputation or dropping rows/columns based on context.\n",
    "\n",
    "3. **Checking for Duplicates:**\n",
    "   - Duplicate rows are identified, counted, and removed to ensure data uniqueness and prevent bias.\n",
    "\n",
    "4. **Validation:**\n",
    "   - After handling missing data and duplicates, the data is re-checked to confirm integrity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "missing_summary = raw_data.isnull().sum()\n",
    "print(\"Missing Values Summary:\\n\", missing_summary)\n",
    "\n",
    "# Filling missing city values with 'Unknown'\n",
    "raw_data[\"city\"] = raw_data[\"city\"].fillna(\"Unknown\")\n",
    "\n",
    "# Check and document duplicates\n",
    "duplicate_count = raw_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Print duplicate rows if they exist\n",
    "if duplicate_count > 0:\n",
    "    print(\"\\nDuplicate rows:\\n\", raw_data[raw_data.duplicated()])\n",
    "\n",
    "# Remove duplicate rows\n",
    "raw_data = raw_data.drop_duplicates()\n",
    "\n",
    "# Verify changes after handling missing values and duplicates\n",
    "print(\"\\nData after handling missing values and duplicates:\\n\", raw_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning city names documentation\n",
    "\n",
    "The cleaning city names stage focuses on ensuring consistency and standardization in the dataset by processing city names. This involves handling variations in formatting, capitalization, and spelling. Consistent city names are crucial for accurate analysis, grouping, and reporting.\n",
    "\n",
    "**Best Practices Followed:**\n",
    "1. **Normalization Process:**\n",
    "   - A function `normalize_city_name` is created to handle city name inconsistencies. This function:\n",
    "     - Strips leading and trailing whitespace.\n",
    "     - Converts names to title case (e.g., \"new york\" becomes \"New York\").\n",
    "     - Properly formats hyphenated names (e.g., \"los-angeles\" becomes \"Los-Angeles\").\n",
    "\n",
    "2. **Creating a Lookup Table:**\n",
    "   - After normalizing city names, a lookup table is generated. The structure of the table is as follows:\n",
    "     - `clean_city`: The standardized city name.\n",
    "     - `list_of_variants`: A list of raw or uncleaned city names that map to the standardized name.\n",
    "   - This table ensures traceability and provides a reference for re-mapping in future processes.\n",
    "\n",
    "3. **Exporting the Lookup Table:**\n",
    "   - The lookup table is saved as a CSV file (`city_lookup.csv`) for reuse in downstream processes and documentation purposes.\n",
    "\n",
    "\n",
    "**Benefits of This Approach:**\n",
    "- Improved consistency in city-related analysis.\n",
    "- Enhanced traceability with the `list_of_variants` column.\n",
    "- Reusability of the lookup table across multiple datasets or reports.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to normalize city names\n",
    "def normalize_city_name(name):\n",
    "    \"\"\"\n",
    "    Normalize city names to ensure consistent formatting.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): The original city name.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and normalized city name.\n",
    "        - Strips leading and trailing whitespace.\n",
    "        - Capitalizes the first letter of each word and handles hyphens appropriately.\n",
    "    \"\"\"\n",
    "    name = name.strip()  # Strip leading and trailing whitespace\n",
    "    # Split by spaces and hyphens, capitalize each part, and rejoin\n",
    "    parts = re.split(r'(\\s+|-)', name)\n",
    "    name = ''.join(part.capitalize() if part.isalpha() else part for part in parts)\n",
    "    return name\n",
    "\n",
    "\n",
    "# Normalize city names in the raw_data DataFrame\n",
    "raw_data['clean_city'] = raw_data['city'].apply(normalize_city_name)\n",
    "\n",
    "\n",
    "# Create a lookup table\n",
    "city_lookup = (\n",
    "    raw_data.groupby('clean_city')['city']\n",
    "    .unique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'city': 'list_of_variants'})\n",
    ")\n",
    "\n",
    "# Save the lookup table to a CSV file\n",
    "city_lookup.to_csv('city_lookup.csv', index=False)\n",
    "\n",
    "# Verify the lookup table\n",
    "print(\"\\nCity Lookup Table:\\n\", city_lookup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Raed\\\\Documents\\\\P_projects\\\\Lean_project\\\\data'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned data to a parquet file\n",
    "intermediate_data = raw_data.drop(columns=['city'])\n",
    "\n",
    "# specify the path to save the intermediate data\n",
    "intermediate_data_path = data_path() + '\\\\intermediate'+'\\\\intermediate_data.parquet'\n",
    "\n",
    "# Save the intermediate data to a parquet file\n",
    "intermediate_data.to_parquet(intermediate_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
