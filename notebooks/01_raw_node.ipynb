{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw to intermediate Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import data_path, list_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Stage Documentation\n",
    "\n",
    "### The loading stage focuses on ensuring data is correctly ingested with proper data types and meaningful column names.\n",
    "\n",
    "**Best Practices Followed:**\n",
    "1. **Defining Data Types:**\n",
    "   - A `dtype_dict` is created to explicitly specify data types for each column in the dataset. This improves memory efficiency and ensures correct data interpretation.\n",
    "   - Examples include treating `gender` as a categorical variable and `bmi` as a float for precise numerical analysis.\n",
    "\n",
    "2. **Using a Column Lookup Table:**\n",
    "   - A dictionary (`column_lookup`) is used to rename columns to more descriptive and meaningful names. This makes the dataset easier to understand and work with.\n",
    "\n",
    "3. **Efficient Loading:**\n",
    "   - The dataset is loaded using `pd.read_csv` with the `dtype_dict`, minimizing post-load type conversions and errors.\n",
    "\n",
    "4. **Validation:**\n",
    "   - The data types and the first few rows are printed to verify successful loading and renaming.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intermediate\\\\intermediate_data.parquet', 'lookup\\\\city_lookup.csv', 'raw\\\\sample_set_1 1-1.csv']\n"
     ]
    }
   ],
   "source": [
    "# Prin the list of data files\n",
    "print(list_data_files())\n",
    "\n",
    "# Define the path to the raw data file\n",
    "raw_data_path =  data_path()+ \"\\\\\" + 'raw\\\\sample_set_1 1-1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_code                 int64\n",
      "age                         int64\n",
      "gender                   category\n",
      "policy_number               int64\n",
      "cms_score                   int64\n",
      "icd_code                 category\n",
      "icd_description    string[python]\n",
      "city               string[python]\n",
      "claim_type               category\n",
      "bmi                       float64\n",
      "dtype: object\n",
      "   member_code  age gender  policy_number  cms_score icd_code  \\\n",
      "0   1961848012   78      M       26730932          4      E11   \n",
      "1   1961848012   78      M       26730932          4      E11   \n",
      "2   1961848012   78      M       26730932          4   E11.33   \n",
      "3   1961848012   78      M       26730932          4   E11.33   \n",
      "4   1961848012   78      M       26730932          4   E11.42   \n",
      "\n",
      "                                     icd_description    city claim_type    bmi  \n",
      "0                           Type 2 diabetes mellitus  RIYADH          I  31.25  \n",
      "1                           Type 2 diabetes mellitus  RIYADH          O  31.25  \n",
      "2  Type 2 diabetes mellitus with proliferative re...  RIYADH          I  31.25  \n",
      "3  Type 2 diabetes mellitus with proliferative re...  RIYADH          O  31.25  \n",
      "4  Type 2 diabetes mellitus with diabetic polyneu...  RIYADH          I  31.25  \n"
     ]
    }
   ],
   "source": [
    "# Define the data types for each column in the dataset\n",
    "dtype_dict = {\n",
    "    \"MEMBER_CODE\": \"int64\",    # De-identified member ID, stored as float to match dataset format\n",
    "    \"Age\": \"int64\",             # Age of the member\n",
    "    \"GENDER\": \"category\",       # Gender is a categorical variable\n",
    "    \"POLICY_NO\": \"int64\",       # Policy number, stored as integer\n",
    "    \"CMS_Score\": \"int64\",       # Charlson comorbidity index score, stored as integer\n",
    "    \"ICD_CODE\": \"category\",     # ICD-10 codes are categorical\n",
    "    \"ICD_desc\": \"string\",       # ICD-10 description as a string\n",
    "    \"City\": \"string\",           # City as a string, handling missing values separately\n",
    "    \"CLAIM_TYPE\": \"category\",   # Claim type is categorical\n",
    "    \"BMI\": \"float64\"            # BMI as a float\n",
    "}\n",
    "\n",
    "# Column renaming lookup table\n",
    "column_lookup = {\n",
    "    \"MEMBER_CODE\": \"member_code\",\n",
    "    \"Age\": \"age\",\n",
    "    \"GENDER\": \"gender\",\n",
    "    \"POLICY_NO\": \"policy_number\",\n",
    "    \"CMS_Score\": \"cms_score\",\n",
    "    \"ICD_CODE\": \"icd_code\",\n",
    "    \"ICD_desc\": \"icd_description\",\n",
    "    \"City\": \"city\",\n",
    "    \"CLAIM_TYPE\": \"claim_type\",\n",
    "    \"BMI\": \"bmi\"\n",
    "}\n",
    "\n",
    "\n",
    "# Load the dataset with specified data types\n",
    "raw_data = pd.read_csv(raw_data_path, dtype=dtype_dict)\n",
    "\n",
    "# Rename columns using the lookup table\n",
    "raw_data.rename(columns=column_lookup, inplace=True)\n",
    "\n",
    "# Verify the data types after loading\n",
    "print(raw_data.dtypes)\n",
    "\n",
    "# Display the first few rows to confirm successful loading\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data and Duplicates Documentation\n",
    "\n",
    "### The second stage focuses on ensuring data integrity by handling missing values and duplicates.\n",
    "\n",
    "**Best Practices Followed:**\n",
    "1. **Identifying Missing Data:**\n",
    "   - A summary of missing values is generated to identify columns with missing entries.\n",
    "\n",
    "2. **Handling Missing Data:**\n",
    "   - Missing values in the `city` column are replaced with \"Unknown\" as an example strategy.\n",
    "   - Other strategies can include imputation or dropping rows/columns based on context.\n",
    "\n",
    "3. **Checking for Duplicates:**\n",
    "   - Duplicate rows are identified, counted, and removed to ensure data uniqueness and prevent bias.\n",
    "\n",
    "4. **Validation:**\n",
    "   - After handling missing data and duplicates, the data is re-checked to confirm integrity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Summary:\n",
      " member_code           0\n",
      "age                   0\n",
      "gender                0\n",
      "policy_number         0\n",
      "cms_score             0\n",
      "icd_code              0\n",
      "icd_description       0\n",
      "city               4700\n",
      "claim_type            0\n",
      "bmi                   0\n",
      "dtype: int64\n",
      "Number of duplicate rows: 2\n",
      "\n",
      "Duplicate rows:\n",
      "          member_code  age gender  policy_number  cms_score icd_code  \\\n",
      "35671  1011590000000   64      M      202320252          3      E11   \n",
      "35695  1011590000000   64      M      202320252          3      I10   \n",
      "\n",
      "                        icd_description    city claim_type        bmi  \n",
      "35671          Type 2 diabetes mellitus  JEDDAH          O  24.691358  \n",
      "35695  Essential (primary) hypertension  JEDDAH          O  24.691358  \n",
      "\n",
      "Data after handling missing values and duplicates:\n",
      "    member_code  age gender  policy_number  cms_score icd_code  \\\n",
      "0   1961848012   78      M       26730932          4      E11   \n",
      "1   1961848012   78      M       26730932          4      E11   \n",
      "2   1961848012   78      M       26730932          4   E11.33   \n",
      "3   1961848012   78      M       26730932          4   E11.33   \n",
      "4   1961848012   78      M       26730932          4   E11.42   \n",
      "\n",
      "                                     icd_description    city claim_type    bmi  \n",
      "0                           Type 2 diabetes mellitus  RIYADH          I  31.25  \n",
      "1                           Type 2 diabetes mellitus  RIYADH          O  31.25  \n",
      "2  Type 2 diabetes mellitus with proliferative re...  RIYADH          I  31.25  \n",
      "3  Type 2 diabetes mellitus with proliferative re...  RIYADH          O  31.25  \n",
      "4  Type 2 diabetes mellitus with diabetic polyneu...  RIYADH          I  31.25  \n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "missing_summary = raw_data.isnull().sum()\n",
    "print(\"Missing Values Summary:\\n\", missing_summary)\n",
    "\n",
    "# Filling missing city values with 'Unknown'\n",
    "raw_data[\"city\"] = raw_data[\"city\"].fillna(\"Unknown\")\n",
    "\n",
    "# Check and document duplicates\n",
    "duplicate_count = raw_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Print duplicate rows if they exist\n",
    "if duplicate_count > 0:\n",
    "    print(\"\\nDuplicate rows:\\n\", raw_data[raw_data.duplicated()])\n",
    "\n",
    "# Remove duplicate rows\n",
    "raw_data = raw_data.drop_duplicates()\n",
    "\n",
    "# Verify changes after handling missing values and duplicates\n",
    "print(\"\\nData after handling missing values and duplicates:\\n\", raw_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning city names documentation\n",
    "\n",
    "The cleaning city names stage focuses on ensuring consistency and standardization in the dataset by processing city names. This involves handling variations in formatting, capitalization, and spelling. Consistent city names are crucial for accurate analysis, grouping, and reporting.\n",
    "\n",
    "**Best Practices Followed:**\n",
    "1. **Normalization Process:**\n",
    "   - A function `normalize_city_name` is created to handle city name inconsistencies. This function:\n",
    "     - Strips leading and trailing whitespace.\n",
    "     - Converts names to title case (e.g., \"new york\" becomes \"New York\").\n",
    "     - Properly formats hyphenated names (e.g., \"los-angeles\" becomes \"Los-Angeles\").\n",
    "\n",
    "2. **Creating a Lookup Table:**\n",
    "   - After normalizing city names, a lookup table is generated. The structure of the table is as follows:\n",
    "     - `clean_city`: The standardized city name.\n",
    "     - `list_of_variants`: A list of raw or uncleaned city names that map to the standardized name.\n",
    "   - This table ensures traceability and provides a reference for re-mapping in future processes.\n",
    "\n",
    "3. **Exporting the Lookup Table:**\n",
    "   - The lookup table is saved as a CSV file (`city_lookup.csv`) for reuse in downstream processes and documentation purposes.\n",
    "\n",
    "\n",
    "**Benefits of This Approach:**\n",
    "- Improved consistency in city-related analysis.\n",
    "- Enhanced traceability with the `list_of_variants` column.\n",
    "- Reusability of the lookup table across multiple datasets or reports.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "City Lookup Table:\n",
      "          clean_city   list_of_variants\n",
      "0              Abha             [Abha]\n",
      "1              Afif             [AFIF]\n",
      "2             Aflaj            [AFLAJ]\n",
      "3           Al Baha          [AL BAHA]\n",
      "4         Al Dwadmi        [AL DWADMI]\n",
      "..              ...                ...\n",
      "59          Unknown          [Unknown]\n",
      "60  Wadi Al Dawasir  [WADI AL DAWASIR]\n",
      "61             Wajh             [WAJH]\n",
      "62            Yanbu            [YANBU]\n",
      "63            Zulfi            [ZULFI]\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to normalize city names\n",
    "def normalize_city_name(name):\n",
    "    \"\"\"\n",
    "    Normalize city names to ensure consistent formatting.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): The original city name.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and normalized city name.\n",
    "        - Strips leading and trailing whitespace.\n",
    "        - Capitalizes the first letter of each word and handles hyphens appropriately.\n",
    "    \"\"\"\n",
    "    name = name.strip()  # Strip leading and trailing whitespace\n",
    "    # Split by spaces and hyphens, capitalize each part, and rejoin\n",
    "    parts = re.split(r'(\\s+|-)', name)\n",
    "    name = ''.join(part.capitalize() if part.isalpha() else part for part in parts)\n",
    "    return name\n",
    "\n",
    "\n",
    "# Normalize city names in the raw_data DataFrame\n",
    "raw_data['clean_city'] = raw_data['city'].apply(normalize_city_name)\n",
    "\n",
    "\n",
    "# Create a lookup table\n",
    "city_lookup = (\n",
    "    raw_data.groupby('clean_city')['city']\n",
    "    .unique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'city': 'list_of_variants'})\n",
    ")\n",
    "\n",
    "# Save the lookup table to a CSV file\n",
    "city_lookup.to_csv('..\\\\data\\\\lookup\\\\city_lookup.csv', index=False)\n",
    "\n",
    "# Verify the lookup table\n",
    "print(\"\\nCity Lookup Table:\\n\", city_lookup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Checks Documentation\n",
    "\n",
    "### The data quality checks phase ensures the dataset is accurate, consistent, and logically sound for analysis. \n",
    "\n",
    "**Steps to be Implemented:**\n",
    "\n",
    "1. **Logical Value Checks:**\n",
    "   - Validate values within logical ranges for key variables:\n",
    "     - `age`: Ensure all ages are within a plausible range (e.g., 0-120).\n",
    "     - `bmi`: Confirm all BMI values fall within a reasonable range (e.g., 10-80).\n",
    "     - `gender`: Ensure only valid values are present (e.g., \"M\", \"F\").\n",
    "\n",
    "2. **Consistency Check for Member Data:**\n",
    "   - Verify that variables that should not change across rows for a member (e.g., `member_code`, `gender`) are consistent.\n",
    "\n",
    "3. **ICD Code and Description Lookup:**\n",
    "   - Create a unique lookup table of `icd_code` and `icd_description` to identify duplicate or erroneous mappings.\n",
    "\n",
    "4. **Save Intermediate Quality Report:**\n",
    "   - Document any issues found during checks and save.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "BMI values that are extreme: [{'bmi': 85.61236623, 'member_code': 1000460000000}, {'bmi': 90.81632653, 'member_code': 1009970000000}, {'bmi': 90.81632653, 'member_code': 1009970000000}, {'bmi': 90.81632653, 'member_code': 1009970000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 104.0582726, 'member_code': 1016820000000}, {'bmi': 90.81632653, 'member_code': 1074890000000}, {'bmi': 90.81632653, 'member_code': 1074890000000}, {'bmi': 90.81632653, 'member_code': 1074890000000}, {'bmi': 80.98477486, 'member_code': 1077330000000}, {'bmi': 80.98477486, 'member_code': 1077330000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m invalid_age_rows\u001b[38;5;241m.\u001b[39mempty, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge values that are not logical: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_age_rows[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmember_code\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m invalid_bmi_rows \u001b[38;5;241m=\u001b[39m raw_data[\u001b[38;5;241m~\u001b[39mraw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmi\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m80\u001b[39m)]\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m invalid_bmi_rows\u001b[38;5;241m.\u001b[39mempty, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBMI values that are extreme: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_bmi_rows[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmi\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmember_code\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: BMI values that are extreme: [{'bmi': 85.61236623, 'member_code': 1000460000000}, {'bmi': 90.81632653, 'member_code': 1009970000000}, {'bmi': 90.81632653, 'member_code': 1009970000000}, {'bmi': 90.81632653, 'member_code': 1009970000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 88.7755102, 'member_code': 1016020000000}, {'bmi': 104.0582726, 'member_code': 1016820000000}, {'bmi': 90.81632653, 'member_code': 1074890000000}, {'bmi': 90.81632653, 'member_code': 1074890000000}, {'bmi': 90.81632653, 'member_code': 1074890000000}, {'bmi': 80.98477486, 'member_code': 1077330000000}, {'bmi': 80.98477486, 'member_code': 1077330000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}, {'bmi': 82.37308529, 'member_code': 1102200000000}]"
     ]
    }
   ],
   "source": [
    "# 1 - Logical checks\n",
    "invalid_age_rows = raw_data[~raw_data['age'].between(0, 120)]\n",
    "assert invalid_age_rows.empty, f\"Age values that are not logical: {invalid_age_rows[['age', 'member_code']].to_dict(orient='records')}\"\n",
    "\n",
    "invalid_bmi_rows = raw_data[~raw_data['bmi'].between(10, 80)]\n",
    "assert invalid_bmi_rows.empty, f\"BMI values that are extreme: {invalid_bmi_rows[['bmi', 'member_code']].to_dict(orient='records')}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent rows due to gender:\n",
      "            member_code gender\n",
      "121        720035000000      M\n",
      "131        720035000000      F\n",
      "144        760902000000      M\n",
      "176        760902000000      F\n",
      "244       1000110000000      F\n",
      "...                 ...    ...\n",
      "173196    2502550000000      F\n",
      "173476    2530880000000      M\n",
      "173477    2530880000000      F\n",
      "173577  247070000000000      M\n",
      "173583  247070000000000      F\n",
      "\n",
      "[5738 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2- Consistency checks for member_code gender\n",
    "valid_genders = [\"M\", \"F\"]\n",
    "assert raw_data['gender'].isin(valid_genders).all(), \"Invalid gender values found.\"\n",
    "\n",
    "# Group by member_code and check for consistent gender\n",
    "member_gender_consistency = raw_data.groupby('member_code')['gender']\n",
    "\n",
    "# Identify inconsistencies\n",
    "inconsistent_rows = member_gender_consistency.transform(lambda group: group.nunique() > 1)\n",
    "inconsistent_gender_members = raw_data[inconsistent_rows][['member_code', 'gender']].drop_duplicates()\n",
    "\n",
    "print(\"Inconsistent rows due to gender:\")\n",
    "print(inconsistent_gender_members)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate ICD codes: 0\n",
      "Number of missing ICD descriptions: 0\n"
     ]
    }
   ],
   "source": [
    "# Create unique lookup table\n",
    "icd_lookup = raw_data[['icd_code', 'icd_description']].drop_duplicates()\n",
    "\n",
    "# Check for duplicates or missing values\n",
    "duplicate_icd = icd_lookup['icd_code'].duplicated().sum()\n",
    "print(f\"Number of duplicate ICD codes: {duplicate_icd}\")\n",
    "missing_icd_desc = icd_lookup['icd_description'].isnull().sum()\n",
    "print(f\"Number of missing ICD descriptions: {missing_icd_desc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality report saved as quality_report.json in the reports directory.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy.int64 to native Python int for JSON serialization\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, (np.int64, np.float64)):\n",
    "        return int(obj)\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "\n",
    "# Save intermediate quality report\n",
    "quality_issues = {\n",
    "    \"Duplicate ICD Codes\": int(duplicate_icd),\n",
    "    \"Missing ICD Descriptions\": int(missing_icd_desc),\n",
    "    \"Invalid/Extreme Age Rows\": invalid_age_rows[['age', 'member_code']].to_dict(orient='records') if not invalid_age_rows.empty else [],\n",
    "    \"Invalid/Extreme BMI Rows\": invalid_bmi_rows[['bmi', 'member_code']].to_dict(orient='records') if not invalid_bmi_rows.empty else [],\n",
    "    \"Members code with inconsistent Gender\": inconsistent_gender_members.index.tolist() if not inconsistent_gender_members.empty else [],\n",
    "}\n",
    "\n",
    "with open('..\\\\reports\\\\raw_data_quality_report.json', 'w') as f:\n",
    "    json.dump(quality_issues, f, indent=4, default=convert_to_serializable)\n",
    "\n",
    "print(\"Quality report saved as quality_report.json in the reports directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing the quality issues of the data\n",
    "\n",
    "- The `non_unique_member_codes.csv` file documents the identified `member_code` issues.\n",
    "- To adress this we will create a unique ID by grouping `policy_number`, `member_code`, `gender`, and `age` to differentiate separate individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unique_id(intermediate_data):\n",
    "    \"\"\"\n",
    "    Assigns a unique ID to individuals by grouping based on policy_number, member_code, gender, and age.\n",
    "\n",
    "    Parameters:\n",
    "    intermediate_data (DataFrame): The DataFrame containing the intermediate data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The DataFrame with an additional column 'unique_id'.\n",
    "    \"\"\"\n",
    "    intermediate_data['unique_id'] = (\n",
    "        intermediate_data.groupby(['policy_number', 'member_code', 'gender', 'age'],  observed=True)\n",
    "        .ngroup()\n",
    "        .astype(str)  # Convert the unique ID to a string\n",
    "\n",
    "    )\n",
    "    return intermediate_data\n",
    "\n",
    "\n",
    "# Assign a unique ID for individuals by grouping\n",
    "raw_data = assign_unique_id(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 173770 entries, 0 to 173771\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count   Dtype   \n",
      "---  ------           --------------   -----   \n",
      " 0   member_code      173770 non-null  int64   \n",
      " 1   age              173770 non-null  int64   \n",
      " 2   gender           173770 non-null  category\n",
      " 3   policy_number    173770 non-null  int64   \n",
      " 4   cms_score        173770 non-null  int64   \n",
      " 5   icd_code         173770 non-null  category\n",
      " 6   icd_description  173770 non-null  string  \n",
      " 7   city             173770 non-null  string  \n",
      " 8   claim_type       173770 non-null  category\n",
      " 9   bmi              173770 non-null  float64 \n",
      " 10  clean_city       173770 non-null  object  \n",
      " 11  unique_id        173770 non-null  object  \n",
      "dtypes: category(3), float64(1), int64(4), object(2), string(2)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned data to a parquet file\n",
    "intermediate_data = raw_data.drop(columns=['city'])\n",
    "intermediate_data.rename(columns={'clean_city': 'city'}, inplace=True)\n",
    "\n",
    "# specify the path to save the intermediate data\n",
    "intermediate_data_path = data_path() + '\\\\intermediate'+'\\\\intermediate_data.parquet'\n",
    "\n",
    "# Save the intermediate data to a parquet file\n",
    "intermediate_data.to_parquet(intermediate_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intermediate_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m intermediate_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'intermediate_data' is not defined"
     ]
    }
   ],
   "source": [
    "intermediate_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
