{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion\n",
    "\n",
    "### The loading stage focuses on ensuring data is correctly ingested with proper data types and meaningful column names.\n",
    "\n",
    "**Best Practices Followed:**\n",
    "1. **Defining Data Types:**\n",
    "   - A `dtype_dict` is created to explicitly specify data types for each column in the dataset. This improves memory efficiency and ensures correct data interpretation.\n",
    "   - Examples include treating `gender` as a categorical variable and `bmi` as a float for precise numerical analysis.\n",
    "\n",
    "2. **Using a Column Lookup Table:**\n",
    "   - A dictionary (`column_lookup`) is used to rename columns to more descriptive and meaningful names. This makes the dataset easier to understand and work with.\n",
    "\n",
    "3. **Efficient Loading:**\n",
    "   - The dataset is loaded using `pd.read_csv` with the `dtype_dict`, minimizing post-load type conversions and errors.\n",
    "\n",
    "4. **Validation:**\n",
    "   - The data types and the first few rows are printed to verify successful loading and renaming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from utils import data_path, list_data_files\n",
    "\n",
    "# Prin the list of data files\n",
    "print(list_data_files())\n",
    "\n",
    "# Define the path to the raw data file\n",
    "raw_data_path =  data_path()+ \"\\\\\" + 'raw\\\\sample_set_1 1-1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data types for each column in the dataset\n",
    "dtype_dict = {\n",
    "    \"MEMBER_CODE\": \"int64\",    # De-identified member ID, stored as float to match dataset format\n",
    "    \"Age\": \"int64\",             # Age of the member\n",
    "    \"GENDER\": \"category\",       # Gender is a categorical variable\n",
    "    \"POLICY_NO\": \"int64\",       # Policy number, stored as integer\n",
    "    \"CMS_Score\": \"int64\",       # Charlson comorbidity index score, stored as integer\n",
    "    \"ICD_CODE\": \"category\",     # ICD-10 codes are categorical\n",
    "    \"ICD_desc\": \"string\",       # ICD-10 description as a string\n",
    "    \"City\": \"string\",           # City as a string, handling missing values separately\n",
    "    \"CLAIM_TYPE\": \"category\",   # Claim type is categorical\n",
    "    \"BMI\": \"float64\"            # BMI as a float\n",
    "}\n",
    "\n",
    "# Column renaming lookup table\n",
    "column_lookup = {\n",
    "    \"MEMBER_CODE\": \"member_code\",\n",
    "    \"Age\": \"age\",\n",
    "    \"GENDER\": \"gender\",\n",
    "    \"POLICY_NO\": \"policy_number\",\n",
    "    \"CMS_Score\": \"cms_score\",\n",
    "    \"ICD_CODE\": \"icd_code\",\n",
    "    \"ICD_desc\": \"icd_description\",\n",
    "    \"City\": \"city\",\n",
    "    \"CLAIM_TYPE\": \"claim_type\",\n",
    "    \"BMI\": \"bmi\"\n",
    "}\n",
    "\n",
    "\n",
    "# Load the dataset with specified data types\n",
    "raw_data = pd.read_csv(raw_data_path, dtype=dtype_dict)\n",
    "\n",
    "# Rename columns using the lookup table\n",
    "raw_data.rename(columns=column_lookup, inplace=True)\n",
    "\n",
    "# Verify the data types after loading\n",
    "print(raw_data.dtypes)\n",
    "\n",
    "# Display the first few rows to confirm successful loading\n",
    "print(raw_data.head())\n",
    "\n",
    "# Save the cleaned data to Parquet format for efficient storage and column type preservation\n",
    "raw_data.to_parquet(\"..\\\\data\\\\raw\\\\diabetic_claims.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "## Handling Missing Data and Duplicates Documentation\n",
    "\n",
    "1. **Identifying Missing Data:**\n",
    "   - A summary of missing values is generated to identify columns with missing entries.\n",
    "\n",
    "2. **Handling Missing Data:**\n",
    "   - Missing values in the `city` column are replaced with \"Unknown\" as an example strategy.\n",
    "      - there are `4700` missing values for `city`  \n",
    "   - Other strategies can include imputation or dropping rows/columns based on context.\n",
    "\n",
    "3. **Checking for Duplicates:**\n",
    "   - Duplicate rows are identified, counted, and removed to ensure data uniqueness and prevent bias. \n",
    "      - There are `2` duplicate rows\n",
    "   - Identified that `claim_type` is a duplicate of another row (I and O values). To test this we check if rows with an I value have a identical row with an O value\n",
    "      - Number of rows with 'I' value that have identical rows with 'O' value: 34233 out of 34235\n",
    "\n",
    "4. **Validation:**\n",
    "   - After handling missing data and duplicates, the data is re-checked to confirm integrity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "missing_summary = raw_data.isnull().sum()\n",
    "print(\"Missing Values Summary:\\n\", missing_summary)\n",
    "\n",
    "# Filling missing city values with 'Unknown'\n",
    "raw_data[\"city\"] = raw_data[\"city\"].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and document duplicates\n",
    "duplicate_count = raw_data.duplicated().sum()\n",
    "display(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Print duplicate rows if they exist\n",
    "if duplicate_count > 0:\n",
    "    display(\"Duplicate rows:\", raw_data[raw_data.duplicated()])\n",
    "\n",
    "# Remove duplicate rows\n",
    "raw_data = raw_data.drop_duplicates()\n",
    "\n",
    "# Verify changes after handling missing values and duplicates\n",
    "display(\"Data after handling missing values and duplicates:\", raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if the claim_type column with values 'I' and 'O' are identical\n",
    "\n",
    "# Separate the DataFrame into two subsets: one with 'I' and one with 'O'\n",
    "df_I = raw_data[raw_data['claim_type'] == 'I']\n",
    "df_O = raw_data[raw_data['claim_type'] == 'O']\n",
    "\n",
    "# Merge the subsets on all columns except 'claim_type' to find identical rows\n",
    "common_columns = [col for col in raw_data.columns if col != 'claim_type']\n",
    "merged_df = pd.merge(df_I, df_O, on=common_columns, suffixes=('_I', '_O'))\n",
    "\n",
    "# Check if rows with 'I' have an identical row with 'O'\n",
    "identical_rows = merged_df[common_columns]\n",
    "\n",
    "# Quantify the number of identical rows\n",
    "num_identical_rows = len(identical_rows)\n",
    "\n",
    "# Print the result\n",
    "display(\"Identical rows with 'I' and 'O' claim_type:\")\n",
    "display(identical_rows)\n",
    "display(f\"Number of rows with 'I' value that have identical rows with 'O' value: {num_identical_rows} out of {len(df_I)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Checks Documentation\n",
    "\n",
    "### The data quality checks phase ensures the dataset is accurate, consistent, and logically sound for analysis. \n",
    "\n",
    "**Steps to be Implemented:**\n",
    "\n",
    "1. **Logical Value Checks:**\n",
    "   - Validate values within logical ranges for key variables:\n",
    "     - `age`: Ensure all ages are within a plausible range (e.g., 0-120).\n",
    "     - `bmi`: Confirm all BMI values fall within a reasonable range (e.g., 10-80).\n",
    "     - `gender`: Ensure only valid values are present (e.g., \"M\", \"F\").\n",
    "\n",
    "2. **Consistency Check for Member Data:**\n",
    "   - Verify that variables that should not change across rows for a member (e.g., `member_code`, `gender`) are consistent.\n",
    "   - We identified that the member_count is does not represent a unique individual, this has been confirmed by conducting a member count grouped by policy_number, member_code, age and gender (show table). It is plausable that the member code represents a famliy unit with multiple individuals when applicable.\n",
    "   - This has been flagged to create a unique identifier for an individual.\n",
    "   - In addition to create a feature table indicating the family unit size across policy_number and member_code for further analysis. \n",
    "\n",
    "3. **ICD Code and Description Lookup:**\n",
    "   - Create a unique lookup table of `icd_code` and `icd_description` to identify duplicate or erroneous mappings.\n",
    "\n",
    "4. **Save Intermediate Quality Report:**\n",
    "   - Document any issues found during checks and save.\n",
    "\n",
    "5.  **Addressing the quality issues of the data:**\n",
    "   - The `non_unique_member_codes.csv` file documents the identified `member_code` issues.\n",
    "   - To adress this we will create a unique ID by grouping `policy_number`, `member_code`, `gender`, and `age` to differentiate separate individuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Logical checks\n",
    "invalid_age_rows = raw_data[~raw_data['age'].between(0, 120)]\n",
    "assert invalid_age_rows.empty, f\"Age values that are not logical: {invalid_age_rows[['age', 'member_code']].to_dict(orient='records')}\"\n",
    "\n",
    "invalid_bmi_rows = raw_data[~raw_data['bmi'].between(10, 80)]\n",
    "assert invalid_bmi_rows.empty, f\"BMI values that are extreme: {invalid_bmi_rows[['bmi', 'member_code']].to_dict(orient='records')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent rows due to gender:\n",
      "            member_code gender\n",
      "121        720035000000      M\n",
      "131        720035000000      F\n",
      "144        760902000000      M\n",
      "176        760902000000      F\n",
      "244       1000110000000      F\n",
      "...                 ...    ...\n",
      "173196    2502550000000      F\n",
      "173476    2530880000000      M\n",
      "173477    2530880000000      F\n",
      "173577  247070000000000      M\n",
      "173583  247070000000000      F\n",
      "\n",
      "[5738 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2- Consistency checks for member_code gender\n",
    "valid_genders = [\"M\", \"F\"]\n",
    "assert raw_data['gender'].isin(valid_genders).all(), \"Invalid gender values found.\"\n",
    "\n",
    "# Group by member_code and check for consistent gender\n",
    "member_gender_consistency = raw_data.groupby(['member_code'])['gender']\n",
    "\n",
    "# Identify inconsistencies\n",
    "inconsistent_rows = member_gender_consistency.transform(lambda group: group.nunique() > 1)\n",
    "inconsistent_gender_members = raw_data[inconsistent_rows][['member_code', 'gender']].drop_duplicates()\n",
    "\n",
    "print(\"Inconsistent rows due to gender:\")\n",
    "print(inconsistent_gender_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_count</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_count  frequency\n",
       "0             1      13555\n",
       "1             2       1678\n",
       "2             3        271\n",
       "3             4        132\n",
       "4             5         55\n",
       "5             6         14\n",
       "6             7          6\n",
       "7             8          4\n",
       "8             9          1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3- checking the frequency of member counts per policy number, member code, gender and age\n",
    "member_table = raw_data[['policy_number', 'member_code', 'gender', 'age']].drop_duplicates()\n",
    "grouped_counts = member_table.groupby(['policy_number', 'member_code']).size().reset_index(name='member_count')\n",
    "\n",
    "# Create a table of the counts of counts\n",
    "counts_of_counts = grouped_counts['member_count'].value_counts().reset_index()\n",
    "counts_of_counts.columns = ['member_count', 'frequency']\n",
    "counts_of_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_number</th>\n",
       "      <th>member_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>26730932</td>\n",
       "      <td>720035000000</td>\n",
       "      <td>M</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>26730932</td>\n",
       "      <td>720035000000</td>\n",
       "      <td>F</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>26730932</td>\n",
       "      <td>760902000000</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>26730932</td>\n",
       "      <td>760902000000</td>\n",
       "      <td>F</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>202320252</td>\n",
       "      <td>1000110000000</td>\n",
       "      <td>F</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173196</th>\n",
       "      <td>30894217</td>\n",
       "      <td>2502550000000</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173476</th>\n",
       "      <td>26730932</td>\n",
       "      <td>2530880000000</td>\n",
       "      <td>M</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173477</th>\n",
       "      <td>26730932</td>\n",
       "      <td>2530880000000</td>\n",
       "      <td>F</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173577</th>\n",
       "      <td>26955367</td>\n",
       "      <td>247070000000000</td>\n",
       "      <td>M</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173583</th>\n",
       "      <td>26955367</td>\n",
       "      <td>247070000000000</td>\n",
       "      <td>F</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11343 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        policy_number      member_code gender  age\n",
       "121          26730932     720035000000      M   78\n",
       "131          26730932     720035000000      F   72\n",
       "144          26730932     760902000000      M   71\n",
       "176          26730932     760902000000      F   67\n",
       "244         202320252    1000110000000      F   58\n",
       "...               ...              ...    ...  ...\n",
       "173196       30894217    2502550000000      F   56\n",
       "173476       26730932    2530880000000      M   68\n",
       "173477       26730932    2530880000000      F   66\n",
       "173577       26955367  247070000000000      M   73\n",
       "173583       26955367  247070000000000      F   68\n",
       "\n",
       "[11343 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = member_table[member_table.duplicated(subset=['member_code'], keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique lookup table\n",
    "icd_lookup = raw_data[['icd_code', 'icd_description']].drop_duplicates()\n",
    "\n",
    "# Check for duplicates or missing values\n",
    "duplicate_icd = icd_lookup['icd_code'].duplicated().sum()\n",
    "print(f\"Number of duplicate ICD codes: {duplicate_icd}\")\n",
    "missing_icd_desc = icd_lookup['icd_description'].isnull().sum()\n",
    "print(f\"Number of missing ICD descriptions: {missing_icd_desc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy.int64 to native Python int for JSON serialization\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, (np.int64, np.float64)):\n",
    "        return int(obj)\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "\n",
    "# Save intermediate quality report\n",
    "quality_issues = {\n",
    "    \"Duplicate ICD Codes\": int(duplicate_icd),\n",
    "    \"Missing ICD Descriptions\": int(missing_icd_desc),\n",
    "    \"Invalid/Extreme Age Rows\": invalid_age_rows[['age', 'member_code']].to_dict(orient='records') if not invalid_age_rows.empty else [],\n",
    "    \"Invalid/Extreme BMI Rows\": invalid_bmi_rows[['bmi', 'member_code']].to_dict(orient='records') if not invalid_bmi_rows.empty else [],\n",
    "    \"Members code with inconsistent Gender\": inconsistent_gender_members.index.tolist() if not inconsistent_gender_members.empty else [],\n",
    "}\n",
    "\n",
    "with open('..\\\\reports\\\\raw_data_quality_report.json', 'w') as f:\n",
    "    json.dump(quality_issues, f, indent=4, default=convert_to_serializable)\n",
    "\n",
    "print(\"Quality report saved as quality_report.json in the reports directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the intermediate data\n",
    "intermediate_data = raw_data.copy()\n",
    "\n",
    "# specify the path to save the intermediate data\n",
    "intermediate_data_path = data_path() + '\\\\intermediate'+'\\\\intermediate_data.parquet'\n",
    "\n",
    "# Save the intermediate data to a parquet file\n",
    "intermediate_data.to_parquet(intermediate_data_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
